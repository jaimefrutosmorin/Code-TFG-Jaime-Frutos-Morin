{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4e995-3347-4785-8c3b-6707740a8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182875e-64e7-48f0-a0a2-ac9b889311ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745fea9-9935-459f-aaf0-de51f4f7dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lifelines matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a642c-d985-4ff3-a7a2-1721d2da6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03f1cf-1242-4118-a0f1-c54318bb57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pyreadstat\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe75ed-5cab-4532-8718-6fafe81bb052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ac00a-2fda-401b-8e1b-b7c7a78697ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = pd.read_excel(r\"C:\\Users\\jaime\\Desktop\\resultados TFG\\Base_TFG_pruebas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9da06-01af-4be4-ba0b-aeb0da84f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e17faf-f6e5-4c26-904a-dcdb6564a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in dfe.columns:\n",
    "    num_faltantes = dfe[columna].isna().sum()\n",
    "    \n",
    "    print(f'Columna: {columna}')\n",
    "    print(f'Número de valores faltantes: {num_faltantes}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89172b60-0e8c-4016-bda9-e6c790f65c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056eb9b-ed10-41af-822b-99d1a371eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.loc[dfe['Sexo'] == 'Hombre', 'Sexo'] = 0\n",
    "dfe.loc[dfe['Sexo'] == 'Mujer', 'Sexo'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b67a4-a988-4edc-ab77-5369b4034eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.loc[dfe['tipo_procedimiento'] == 'ACTP', 'tipo_procedimiento'] = 0\n",
    "dfe.loc[dfe['tipo_procedimiento'] == 'PONTAJE AORTOCORONARIO', 'tipo_procedimiento'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c291b78-0410-4106-b6a8-553572d826ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.loc[dfe['Tipo_intervención_mitral'] == 'Anuloplastia', 'Tipo_intervención_mitral'] = 'anuloplastia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972bee2-3c05-41d8-960a-6142bf80d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = ['HTA', 'DM', 'dislipemia', 'sobrepeso/obesidad', 'fumador', 'exfumador', 'IC', 'IAM', 'SC_intermedio/angina_inestable', 'Angina_estable', 'Antecedente_IAM']  # Especifica las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c5f8e5-b7db-4207-8be8-b3f39bd414ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_transform:\n",
    "    dfe[col] = np.where(dfe[col] == 'SI', 1, 0)\n",
    "dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5c8a5-d7e2-4abe-b70a-ec72dc129bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores repetidos en Nhistoria\n",
    "filas_repetidas = dfe[dfe[\"NHC\"].duplicated(keep=False)]\n",
    "filas_repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f991a6-b394-4359-b4d6-c5a4e544c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = dfe.rename(columns={'sobrepeso/obesidad': 'sobrepeso_obesidad'})\n",
    "dfe = dfe.rename(columns={'SC_intermedio/angina_inestable': 'SC_intermedio_Angina_inestable'})\n",
    "dfe = dfe.rename(columns={' Intervención_mitral': 'Intervencion_mitral'})\n",
    "dfe = dfe.rename(columns={'días_FEVI_pre': 'dias_FEVI_pre'})\n",
    "dfe = dfe.rename(columns={'días_FEVI_post': 'dias_FEVI_post'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c69cbf-123b-4a73-b1a7-6099ca65796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in dfe.columns:\n",
    "    num_faltantes = dfe[columna].isna().sum()\n",
    "    \n",
    "    print(f'Columna: {columna}')\n",
    "    print(f'Número de valores faltantes: {num_faltantes}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14983be1-644e-4bc6-9dd5-9852ffa0cff2",
   "metadata": {},
   "source": [
    "#### Crear variable Tabaquismo_Rec (No fumador = 0, Fumador = 1, Ex Fumador = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c695c0-5635-47a0-a91e-573c20047b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condiciones 'Tabaquismo_Rec'\n",
    "conditions = [\n",
    "    (dfe['fumador'] == 0) & (dfe['exfumador'] == 0),\n",
    "    (dfe['fumador'] == 1) & (dfe['exfumador'] == 0),\n",
    "    (dfe['fumador'] == 0) & (dfe['exfumador'] == 1) \n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "\n",
    "dfe['Tabaquismo_Rec'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "print(\"\\nDataFrame con Tabaquismo_Rec:\")\n",
    "dfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3495a-c03b-431a-b055-3b563b7c2ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c199546-bf17-426a-9b48-494070fe40c7",
   "metadata": {},
   "source": [
    "#### Creamos la variable 'tipo_causa' donde agrupamos las categorías de la varibale 'Causa' en función de si son cardiovasculares o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9361a-70b0-4dc9-94dd-a2b79cdbb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_unicas = dfe['Causa'].unique()\n",
    "categorias_unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e575ebe-7e9b-4185-8602-c447c66c11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "causas_cardiovasculares = ['ICC ', 'ICC', 'IAM', 'Infarto agudo de miocarido', 'ACVA', 'muerte cardiovascular en residencia', 'Muerte  subita cardiovascular', 'Fallo agudo de trasplante cardiaco', 'CARDIOVASCULAR']\n",
    "\n",
    "# Creamos variable 'tipo_causa'\n",
    "dfe['tipo_causa'] = dfe['Causa'].apply(\n",
    "    lambda x: 'Cardiovascular' if isinstance(x, str) and any(kw in x for kw in causas_cardiovasculares) \n",
    "    else ('No Cardiovascular' if isinstance(x, str) else np.nan)\n",
    ")\n",
    "\n",
    "print(dfe['tipo_causa'].value_counts(dropna=False))  # dropna=False para incluir los valores faltantes en el conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7fa680-dfe9-43b7-aaf1-b404b597ddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7949046-ffd1-4a93-959e-028b9a56cf6b",
   "metadata": {},
   "source": [
    "#### Creamos nuevas variables de pacientes que con lesión y que no han sido revascularizados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ffc20-9b75-452a-9df6-24e9df28df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos nuevas variables de pacientes que con lesión y que no han sido revascularizados \n",
    "dfe['DA_sin_revasc'] = ((dfe['DA'] == 1) & (dfe['DA_revasc'] == 0)).astype(int)\n",
    "dfe['Cx_sin_revasc'] = ((dfe['Cx'] == 1) & (dfe['Cx_revasc'] == 0)).astype(int)\n",
    "dfe['CD_sin_revasc'] = ((dfe['CD'] == 1) & (dfe['CD_revasc'] == 0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e7534-b3eb-4ac6-b1dc-26c2dbf8f16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a1d5c5d-c85d-41e5-aa78-f60fef4ae503",
   "metadata": {},
   "source": [
    "#### Creamos la variable 'Muerte_o_Infarto' en función de si el paciente ha fallecido o ha sufrido un infarto en los primeros tres años tras la intervención"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76147a65-3047-45b5-abec-b7dec19a908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la nueva columna 'Muerte_o_Infarto'\n",
    "def calcular_muerte_infarto(row):\n",
    "    limite_dias = 3 * 365\n",
    "\n",
    "    # Caso 1: Muerte=0, Infarto=0\n",
    "    if row['Muerte'] == 0 and row['Infarto'] == 0:\n",
    "        return 0\n",
    "\n",
    "    # Caso 2: Muerte=1, Infarto=1\n",
    "    if row['Muerte'] == 1 and row['Infarto'] == 1:\n",
    "        diferencia_muerte = (row['Fecha_muerte'] - row['Fecha_Intervención']).days if pd.notna(row['Fecha_muerte']) else float('inf')\n",
    "        diferencia_infarto = (row['Fecha_infarto'] - row['Fecha_Intervención']).days if pd.notna(row['Fecha_infarto']) else float('inf')\n",
    "\n",
    "        if diferencia_muerte <= limite_dias or diferencia_infarto <= limite_dias:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Caso 3: Muerte=1, Infarto=0\n",
    "    if row['Muerte'] == 1 and row['Infarto'] == 0:\n",
    "        diferencia_muerte = (row['Fecha_muerte'] - row['Fecha_Intervención']).days if pd.notna(row['Fecha_muerte']) else float('inf')\n",
    "\n",
    "        if diferencia_muerte <= limite_dias:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Caso 4: Muerte=0, Infarto=1\n",
    "    if row['Muerte'] == 0 and row['Infarto'] == 1:\n",
    "        diferencia_infarto = (row['Fecha_infarto'] - row['Fecha_Intervención']).days if pd.notna(row['Fecha_infarto']) else float('inf')\n",
    "\n",
    "        if diferencia_infarto <= limite_dias:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Aplicar la función a cada fila del DataFrame\n",
    "dfe['Muerte_o_Infarto'] = dfe.apply(calcular_muerte_infarto, axis=1)\n",
    "\n",
    "dfe[['Fecha_Intervención', 'Muerte', 'Fecha_muerte', 'Infarto', 'Fecha_infarto', 'Muerte_o_Infarto']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948417c-94b7-46eb-aae1-49dc997eb2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a326d47-6f8a-40f6-a361-9ec5e4483f12",
   "metadata": {},
   "source": [
    "#### Graficamos variables categóricas y realizamos conteo de cada una de las categorías de cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0d43e-5cd5-40ff-ae28-021de58f2744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_cat = ['Sexo', 'Muerte', 'Causa', 'tipo_causa', 'Infarto', 'Nueva_revascularización', 'Ingeso_ICC', 'Tronco_coronario', 'DA', 'Cx', 'CD', \n",
    "           'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Revas_completa', 'dif', 'Vasosrev', 'Vasospre', 'Intervencion_mitral', 'Tipo_intervención_mitral', \n",
    "           'tipo_procedimiento', 'HTA', 'DM', 'dislipemia', 'sobrepeso_obesidad', 'fumador', 'exfumador', 'Tabaquismo_Rec', 'IC', 'IAM', \n",
    "           'SC_intermedio_Angina_inestable', 'Angina_estable', 'Antecedente_IAM', 'Muerte_o_Infarto', 'DA_sin_revasc', 'Cx_sin_revasc', 'CD_sin_revasc'] \n",
    "# Crear un gráfico para cada variable categórica\n",
    "for var in var_cat:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(data=dfe, x=var)\n",
    "    \n",
    "    # Agregar los conteos sobre las barras\n",
    "    ax = plt.gca()\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "    # Título y etiquetas\n",
    "    plt.title(f'Conteo de categorías en {var}', fontsize=16)\n",
    "    plt.xlabel(var, fontsize=14)\n",
    "    plt.ylabel('Conteo', fontsize=14)\n",
    "    \n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff2c26-1e4d-46d2-97cd-c949b91bf149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e4965-a5f1-46d2-a56f-5fd0e9cdb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar los resultados\n",
    "summary_table = []\n",
    "\n",
    "# Iterar sobre cada variable categórica\n",
    "for var in var_cat:\n",
    "    # Obtener los conteos de cada categoría\n",
    "    counts = dfe[var].value_counts(dropna=False)  # Incluir NaN si existe\n",
    "    percentages = dfe[var].value_counts(normalize=True, dropna=False) * 100  # Porcentajes\n",
    "    \n",
    "    # Crear una tabla por cada categoría de la variable\n",
    "    for category, count in counts.items():\n",
    "        percentage = percentages[category]\n",
    "        summary_table.append({\n",
    "            'Variable': var,\n",
    "            'Categoría': category,\n",
    "            'Conteo': count,\n",
    "            'Porcentaje (%)': round(percentage, 2)\n",
    "        })\n",
    "\n",
    "# Convertir la lista a un DataFrame\n",
    "df_summary = pd.DataFrame(summary_table)\n",
    "\n",
    "# Mostrar la tabla\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c4679-05b2-4318-8bee-91b6cd161c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23221af4-cd94-45d4-9889-ddd5aa9906b7",
   "metadata": {},
   "source": [
    "#### Creación variable 'tiempo_meses' (meses transcurridos entre la fecha de intervención y la de muerte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8667598-76f1-48eb-bb99-5f1b1bdb83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos columna para la fecha de fin de seguimiento (última fecha conocida)\n",
    "# Si no tienes una fecha límite clara, podrías usar una fecha fija\n",
    "fecha_fin_seguimiento = pd.Timestamp(\"2024-11-20\")  # Ajusta según sea necesario\n",
    "\n",
    "# Calcular la diferencia en meses entre las fechas\n",
    "dfe['tiempo_meses'] = (\n",
    "    dfe['Fecha_muerte'].fillna(fecha_fin_seguimiento).dt.to_period('M') - \n",
    "    dfe['Fecha_Intervención'].dt.to_period('M')\n",
    ").apply(lambda x: x.n)  # Convertir PeriodIndex a valores numéricos\n",
    "\n",
    "\n",
    "# Mostrar una vista previa\n",
    "dfe[['Fecha_Intervención', 'Fecha_muerte', 'tiempo_meses', 'Muerte']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62483f64-b6fd-4dcd-af5e-b9e29482bd61",
   "metadata": {},
   "source": [
    "#### Graficamos variables numéricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96a134-1da6-4850-b88e-d93c64747354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_num = ['edad_ingreso', 'dias_muerte', 'FEVI_pre', 'dias_FEVI_pre', 'FEVI_post', 'dias_FEVI_post', 'tiempo_meses']\n",
    "# Crear un histograma para cada variable numérica\n",
    "for var in var_num:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    dfe[var].hist(bins=10, edgecolor='black')  \n",
    "    \n",
    "    # Título y etiquetas\n",
    "    plt.title(f'Histograma de {var}', fontsize=16)\n",
    "    plt.xlabel(var, fontsize=14)\n",
    "    plt.ylabel('Frecuencia', fontsize=14)\n",
    "    \n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815b88a-ec2d-41b2-8b90-a94e28a1c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle para generar los histogramas\n",
    "for col in var_num:\n",
    "    plt.figure(figsize=(10, 6))  # Ajustar tamaño de la figura para mejor visibilidad\n",
    "    \n",
    "    # Generar el histograma con más detalles ajustando el número de bins\n",
    "    plt.hist(dfe[col].dropna(), bins=50, color='skyblue', edgecolor='black', alpha=0.7) \n",
    "    \n",
    "    # Personalización del gráfico\n",
    "    plt.title(f'Histograma de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Mostrar el gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd396cd-ab97-4e6c-b764-82249bb48c94",
   "metadata": {},
   "source": [
    "#### Estadística básica de variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65046310-4845-4249-bcb5-3ddba82dcd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar la información de cada variable\n",
    "summary_data = []\n",
    "\n",
    "# Bucle para recorrer cada columna de tipo float64\n",
    "for col in var_num:\n",
    "    # Calcular estadísticas básicas\n",
    "    media = dfe[col].mean()  \n",
    "    mediana = dfe[col].median()  \n",
    "    desviacion_std = dfe[col].std()  \n",
    "    minimo = dfe[col].min() \n",
    "    maximo = dfe[col].max()  \n",
    "    \n",
    "    # Número de valores faltantes (NaN) en la columna\n",
    "    num_faltantes = dfe[col].isna().sum()  # Solo cuenta los NaN, no los 0\n",
    "\n",
    "    # Identificar outliers usando el método del rango intercuartílico (IQR)\n",
    "    Q1 = dfe[col].quantile(0.25)  # Primer cuartil\n",
    "    Q3 = dfe[col].quantile(0.75)  # Tercer cuartil\n",
    "    IQR = Q3 - Q1  # Rango intercuartílico\n",
    "    \n",
    "    # Definir límites para los outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filtrar los valores que son outliers\n",
    "    outliers = dfe[col][(dfe[col] < lower_bound) | (dfe[col] > upper_bound)]\n",
    "    \n",
    "    # Contar cuántos outliers hay\n",
    "    num_outliers = outliers.shape[0]\n",
    "    \n",
    "    # Rango de los outliers (si existen)\n",
    "    if num_outliers > 0:\n",
    "        outlier_min = outliers.min()\n",
    "        outlier_max = outliers.max()\n",
    "    else:\n",
    "        outlier_min, outlier_max = np.nan, np.nan  # Si no hay outliers, asignar NaN\n",
    "\n",
    "    # Agregar la información a la lista\n",
    "    summary_data.append({\n",
    "        'Variable': col,\n",
    "        'Valores Faltantes': num_faltantes,\n",
    "        'Media': media,\n",
    "        'Mediana': mediana,\n",
    "        'Desviación Estándar': desviacion_std,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'Mínimo': minimo,\n",
    "        'Máximo': maximo,\n",
    "        'Número de Outliers': num_outliers,\n",
    "        'Rango de Outliers (Mín)': outlier_min,\n",
    "        'Rango de Outliers (Máx)': outlier_max\n",
    "    })\n",
    "\n",
    "# Crear un DataFrame con el resumen\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "# Mostrar el DataFrame con el resumen\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257a572-f54e-4357-86ae-0746b47c6a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "624e18a5-a564-4303-9bb6-6411da761076",
   "metadata": {},
   "source": [
    "#### Comparación variables entre pacientes con y sin evento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e028ed-057b-4747-9bdb-cfeb879e3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu, shapiro\n",
    "\n",
    "# Separamos grupos (evento y no evento)\n",
    "grupo_evento = dfe[dfe['Muerte'] == 1]  # Pacientes con evento\n",
    "grupo_no_evento = dfe[dfe['Muerte'] == 0]  # Pacientes sin evento\n",
    "\n",
    "# Almacenar resultados\n",
    "resultados_categoricas = []\n",
    "resultados_numericas = []\n",
    "tablas_contingencia = []\n",
    "frecuencias_categoricas = []\n",
    "\n",
    "# Comparación variables categóricas\n",
    "var_cat = ['Sexo', 'Causa', 'tipo_causa', 'Infarto', 'Nueva_revascularización', 'Ingeso_ICC', 'Tronco_coronario', 'DA', 'Cx', 'CD', \n",
    "           'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Revas_completa', 'dif', 'Vasosrev', 'Vasospre', ' Intervencion_mitral', 'Tipo_intervención_mitral', \n",
    "           'tipo_procedimiento', 'HTA', 'DM', 'dislipemia', 'sobrepeso_obesidad', 'fumador', 'exfumador', 'Tabaquismo_Rec', 'IC', 'IAM', \n",
    "           'SC_intermedio_Angina_inestable', 'Angina_estable', 'Antecedente_IAM', 'Muerte_o_Infarto', 'DA_sin_revasc', 'Cx_sin_revasc', 'CD_sin_revasc']\n",
    "\n",
    "for var in var_cat:\n",
    "    if var in dfe.columns:\n",
    "        tabla = pd.crosstab(dfe[var], dfe['Muerte'])  # Tabla de contingencia\n",
    "        chi2, p, _, _ = chi2_contingency(tabla)  # Prueba de chi-cuadrado\n",
    "        \n",
    "        # Guardar tabla de contingencia como DataFrame para exportar a Excel\n",
    "        tabla_reset = tabla.reset_index()\n",
    "        tabla_reset.insert(0, 'Variable', var)  # Agregar nombre de variable\n",
    "        tablas_contingencia.append(tabla_reset)\n",
    "        \n",
    "        # Guardar frecuencias individuales\n",
    "        tabla_frec = dfe[var].value_counts().reset_index()\n",
    "        tabla_frec.columns = ['Valor', 'Frecuencia']\n",
    "        tabla_frec.insert(0, 'Variable', var)\n",
    "        frecuencias_categoricas.append(tabla_frec)\n",
    "        \n",
    "        # Guardar resultado de la prueba\n",
    "        resultados_categoricas.append({'Variable': var, 'Prueba': 'Chi-cuadrado', 'P-valor': p})\n",
    "\n",
    "# Comparación variables numéricas\n",
    "var_num = ['edad_ingreso', 'dias_muerte', 'FEVI_pre', 'dias_FEVI_pre', 'FEVI_post', 'dias_FEVI_post', 'tiempo_meses']\n",
    "\n",
    "for var in var_num:\n",
    "    if var in dfe.columns:\n",
    "        # Evaluar normalidad con Shapiro-Wilk\n",
    "        stat, p_normal = shapiro(dfe[var].dropna())  \n",
    "        \n",
    "        if p_normal > 0.05:  # Distribución normal → Prueba t de Student\n",
    "            test_name = 'Prueba t de Student'\n",
    "            t_stat, p_value = ttest_ind(grupo_evento[var].dropna(), grupo_no_evento[var].dropna(), equal_var=False)\n",
    "        else:  # No normal → Prueba de Mann-Whitney U\n",
    "            test_name = 'Mann-Whitney U'\n",
    "            u_stat, p_value = mannwhitneyu(grupo_evento[var].dropna(), grupo_no_evento[var].dropna())\n",
    "        \n",
    "        # Guardar resultados\n",
    "        resultados_numericas.append({'Variable': var, 'Prueba': test_name, 'P-valor': p_value, 'P-valor Shapiro-Wilk': p_normal})\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_resultados_categoricas = pd.DataFrame(resultados_categoricas).sort_values(by='P-valor')\n",
    "df_resultados_numericas = pd.DataFrame(resultados_numericas).sort_values(by='P-valor')\n",
    "df_tablas_contingencia = pd.concat(tablas_contingencia, ignore_index=True) if tablas_contingencia else pd.DataFrame()\n",
    "df_frecuencias_categoricas = pd.concat(frecuencias_categoricas, ignore_index=True) if frecuencias_categoricas else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf2c31-b97f-42c1-bd82-8aa1f84af71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en un archivo Excel con múltiples hojas\n",
    "nombre_archivo = \"comparacion_muerte_variables.xlsx\"\n",
    "with pd.ExcelWriter(nombre_archivo) as writer:\n",
    "    df_resultados_categoricas.to_excel(writer, sheet_name=\"Variables_Categoricas\", index=False)\n",
    "    df_resultados_numericas.to_excel(writer, sheet_name=\"Variables_Numericas\", index=False)\n",
    "    if not df_tablas_contingencia.empty:\n",
    "        df_tablas_contingencia.to_excel(writer, sheet_name=\"Tablas_Contingencia\", index=False)\n",
    "    if not df_frecuencias_categoricas.empty:\n",
    "        df_frecuencias_categoricas.to_excel(writer, sheet_name=\"Frecuencias_Categoricas\", index=False)\n",
    "\n",
    "print(f\"Resultados guardados en {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92744c3e-a44d-4751-a400-74eec74e31f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777242b3-bc5c-4ef9-bbef-6d16c587ec77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a2ba2-44dc-45d6-b291-be5a7e771ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f1baaf0-3bbe-49e5-b930-00a2e8cb3e2f",
   "metadata": {},
   "source": [
    "#### Comparación variables entre pacientes con y sin evento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ada3c-606b-4194-9760-503432a39dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu, shapiro\n",
    "\n",
    "# Separamos grupos (evento y no evento)\n",
    "grupo_evento = dfe[dfe['Muerte'] == 1]  # Pacientes con evento\n",
    "grupo_no_evento = dfe[dfe['Muerte'] == 0]  # Pacientes sin evento\n",
    "\n",
    "# Almacenamos resultados\n",
    "resultados_categoricas = []\n",
    "resultados_numericas = []\n",
    "\n",
    "# Comparamos variables categóricas\n",
    "var_cat = ['Sexo', 'Causa', 'tipo_causa', 'Infarto', 'Nueva_revascularización', 'Ingeso_ICC', 'Tronco_coronario', 'DA', 'Cx', 'CD', \n",
    "           'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Revas_completa', 'dif', 'Vasosrev', 'Vasospre', ' Intervencion_mitral', 'Tipo_intervención_mitral', \n",
    "           'tipo_procedimiento', 'HTA', 'DM', 'dislipemia', 'sobrepeso_obesidad', 'fumador', 'exfumador', 'Tabaquismo_Rec', 'IC', 'IAM', \n",
    "           'SC_intermedio_Angina_inestable', 'Angina_estable', 'Antecedente_IAM', 'Muerte_o_Infarto', 'DA_sin_revasc', 'Cx_sin_revasc', 'CD_sin_revasc']\n",
    "\n",
    "for var in var_cat:\n",
    "    if var in dfe.columns:\n",
    "        tabla = pd.crosstab(dfe[var], dfe['Muerte'])  # Tabla de contingencia\n",
    "        chi2, p, _, _ = chi2_contingency(tabla)  # Prueba de chi-cuadrado\n",
    "        \n",
    "        # Guardar resultado de la prueba\n",
    "        resultados_categoricas.append({'Variable': var, 'P-valor': p})\n",
    "\n",
    "# Comparamos variables numéricas\n",
    "var_num = ['edad_ingreso', 'dias_muerte', 'FEVI_pre', 'dias_FEVI_pre', 'FEVI_post', 'dias_FEVI_post', 'tiempo_meses']\n",
    "\n",
    "for var in var_num:\n",
    "    if var in dfe.columns:\n",
    "        # Shapiro-Wilk (normalidad)\n",
    "        stat, p_normal = shapiro(dfe[var].dropna())  \n",
    "        \n",
    "        if p_normal > 0.05:  # Distr. normal (t-test)\n",
    "            test_name = 'Prueba t de Student'\n",
    "            t_stat, p_value = ttest_ind(grupo_evento[var].dropna(), grupo_no_evento[var].dropna(), equal_var=False)\n",
    "        else:  # Distr. NO normal (Mann-Whitney U)\n",
    "            test_name = 'Mann-Whitney U'\n",
    "            u_stat, p_value = mannwhitneyu(grupo_evento[var].dropna(), grupo_no_evento[var].dropna())\n",
    "        \n",
    "        # Guardamos resultados\n",
    "        resultados_numericas.append({'Variable': var, 'Prueba': test_name, 'P-valor': p_value, 'P-valor Shapiro-Wilk': p_normal})\n",
    "\n",
    "df_resultados_categoricas = pd.DataFrame(resultados_categoricas)\n",
    "df_resultados_numericas = pd.DataFrame(resultados_numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30751c14-d6e6-4efe-86bb-62da0ffd3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en un archivo Excel con múltiples hojas\n",
    "nombre_archivo = \"comparacion_est_variables.xlsx\"\n",
    "with pd.ExcelWriter(nombre_archivo) as writer:\n",
    "    df_resultados_categoricas.to_excel(writer, sheet_name=\"Variables_Categoricas\", index=False)\n",
    "    df_resultados_numericas.to_excel(writer, sheet_name=\"Variables_Numericas\", index=False)\n",
    "\n",
    "print(f\"Resultados guardados en {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca1933-8a01-4db9-b43b-ba0e71bb88df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2da2b6a-7a51-44ed-9efe-b9539f2e0a9f",
   "metadata": {},
   "source": [
    "##### Tablas de contingencia y de proporciones (variables categóricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7015c0-1252-4e29-be0a-1bdfa4a34c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_cat:\n",
    "    if var in dfe.columns:\n",
    "        # Tabla de contingencia\n",
    "        tabla_contingencia = pd.crosstab(dfe[var], dfe['Muerte'])\n",
    "        print(f\"\\n Tabla de Contingencia - {var}:\")\n",
    "        print(tabla_contingencia)\n",
    "\n",
    "        # Tabla de proporciones\n",
    "        tabla_proporciones = pd.crosstab(dfe[var], dfe['Muerte'], normalize='columns')\n",
    "        print(f\"\\n Tabla de Proporciones - {var}:\")\n",
    "        print(tabla_proporciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1d7a4-8b28-4b12-9da8-83bd601d3db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680cbd8-6542-4cb4-9dd3-f7ca59a0d875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bde2f816-d99c-4ce8-9afc-bbb95dd40515",
   "metadata": {},
   "source": [
    "#### Comparación de variables respecto a Muerte_o_Infarto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fcec8-1544-46e6-b6b7-190ad4cdbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, fisher_exact, ttest_ind, mannwhitneyu, shapiro\n",
    "\n",
    "# Separamos grupos (evento y no evento)\n",
    "grupo_evento = dfe[dfe['Muerte_o_Infarto'] == 1]  # Pacientes con evento\n",
    "grupo_no_evento = dfe[dfe['Muerte_o_Infarto'] == 0]  # Pacientes sin evento\n",
    "\n",
    "# Almacenamos resultados\n",
    "resultados_categoricas = []\n",
    "resultados_numericas = []\n",
    "\n",
    "# Comparamos variables categóricas\n",
    "var_cat = ['Sexo', 'Nueva_revascularización', 'Ingeso_ICC', 'Tronco_coronario', 'DA', 'Cx', 'CD', 'Revas_completa', 'dif', 'Vasosrev', 'Vasospre', \n",
    "           'Intervencion_mitral', 'tipo_procedimiento', 'HTA', 'DM', 'dislipemia', 'sobrepeso_obesidad', 'fumador', 'exfumador', 'IC', 'IAM', \n",
    "           'SC_intermedio_Angina_inestable', 'Angina_estable', 'Antecedente_IAM', 'DA_sin_revasc', 'Cx_sin_revasc', 'CD_sin_revasc']\n",
    "\n",
    "for var in var_cat:\n",
    "    if var in dfe.columns:\n",
    "        tabla = pd.crosstab(dfe[var], dfe['Muerte_o_Infarto'])  # Tabla de contingencia\n",
    "        chi2, p_chi2, _, expected = chi2_contingency(tabla)  # Prueba de chi-cuadrado con frecuencias esperadas\n",
    "        \n",
    "        # Revisar si alguna celda tiene <5 casos\n",
    "        if (expected < 5).any():\n",
    "            # Si alguna frecuencia esperada es menor a 5, usamos Fisher\n",
    "            if tabla.shape == (2, 2):  # Fisher solo para tablas 2x2\n",
    "                _, p_fisher = fisher_exact(tabla)\n",
    "                p_value = p_fisher\n",
    "                test_name = 'Fisher Exact'\n",
    "            else:\n",
    "                p_value = p_chi2  # Para tablas más grandes, mantenemos Chi-cuadrado\n",
    "                test_name = 'Chi-cuadrado (ajustado)'\n",
    "        else:\n",
    "            p_value = p_chi2\n",
    "            test_name = 'Chi-cuadrado'\n",
    "\n",
    "        # Guardar resultado de la prueba\n",
    "        resultados_categoricas.append({'Variable': var, 'Prueba': test_name, 'P-valor': p_value})\n",
    "\n",
    "# Comparamos variables numéricas\n",
    "var_num = ['edad_ingreso', 'FEVI_pre', 'dias_FEVI_pre', 'FEVI_post', 'dias_FEVI_post']\n",
    "\n",
    "for var in var_num:\n",
    "    if var in dfe.columns:\n",
    "        # Shapiro-Wilk (normalidad)\n",
    "        stat, p_normal = shapiro(dfe[var].dropna())  \n",
    "        \n",
    "        if p_normal > 0.05:  # Distr. normal (t-test)\n",
    "            test_name = 'Prueba t de Student'\n",
    "            t_stat, p_value = ttest_ind(grupo_evento[var].dropna(), grupo_no_evento[var].dropna(), equal_var=False)\n",
    "        else:  # Distr. NO normal (Mann-Whitney U)\n",
    "            test_name = 'Mann-Whitney U'\n",
    "            u_stat, p_value = mannwhitneyu(grupo_evento[var].dropna(), grupo_no_evento[var].dropna())\n",
    "        \n",
    "        # Guardamos resultados\n",
    "        resultados_numericas.append({'Variable': var, 'Prueba': test_name, 'P-valor': p_value, 'P-valor Shapiro-Wilk': p_normal})\n",
    "\n",
    "df_resultados_categoricas = pd.DataFrame(resultados_categoricas)\n",
    "df_resultados_numericas = pd.DataFrame(resultados_numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dba51-a219-4f7b-a553-5f9a898d5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en un archivo Excel con múltiples hojas\n",
    "nombre_archivo = \"comparacion_muerteoinfarto.xlsx\"\n",
    "with pd.ExcelWriter(nombre_archivo) as writer:\n",
    "    df_resultados_categoricas.to_excel(writer, sheet_name=\"Variables_Categoricas\", index=False)\n",
    "    df_resultados_numericas.to_excel(writer, sheet_name=\"Variables_Numericas\", index=False)\n",
    "\n",
    "print(f\"Resultados guardados en {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3466bdd-c355-49c0-8f8f-3b93de820383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_cat:\n",
    "    if var in dfe.columns:\n",
    "        # Tabla de contingencia\n",
    "        tabla_contingencia = pd.crosstab(dfe[var], dfe['Muerte_o_Infarto'])\n",
    "        print(f\"\\n Tabla de Contingencia - {var}:\")\n",
    "        print(tabla_contingencia)\n",
    "\n",
    "        # Tabla de proporciones\n",
    "        tabla_proporciones = pd.crosstab(dfe[var], dfe['Muerte_o_Infarto'], normalize='columns')\n",
    "        print(f\"\\n Tabla de Proporciones - {var}:\")\n",
    "        print(tabla_proporciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639601b-8358-4d3c-89c8-861bb5988e7f",
   "metadata": {},
   "source": [
    "###### Distr. proporciones variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54148ab3-d4d3-4e2e-9e2a-3e2d0763cad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "for var in var_cat:\n",
    "    # Calculamos proporciones de cada categoría dentro de los grupos de 'muerte_o_infarto'\n",
    "    prop_dfe = pd.crosstab(dfe[var], dfe['Muerte_o_Infarto'], normalize='columns')\n",
    "    \n",
    "    # Graficamos\n",
    "    prop_dfe.plot(kind='bar', stacked=True, figsize=(8, 6), colormap='Set2')\n",
    "    plt.title(f'Distribución Proporcional de {var} entre Pacientes con y sin Evento', fontsize=14)\n",
    "    plt.xlabel(var, fontsize=12)\n",
    "    plt.ylabel('Proporción', fontsize=12)\n",
    "    plt.xticks(rotation=0)  # Rotar las etiquetas en el eje X si es necesario\n",
    "    plt.legend(title='Muerte o Infarto', loc='upper right', labels=['Sin Evento', 'Con Evento'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa11f8-c2a6-44d0-b79a-fead437016a5",
   "metadata": {},
   "source": [
    "###### Distr. variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d514d-b7ed-4a59-a146-b2bdbacb155d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in var_num:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(dfe[dfe['Muerte_o_Infarto'] == 0][var], kde=True, color=\"blue\", label=\"Sin Evento\", alpha=0.5)\n",
    "    sns.histplot(dfe[dfe['Muerte_o_Infarto'] == 1][var], kde=True, color=\"red\", label=\"Con Evento\", alpha=0.5)\n",
    "    plt.title(f'Distribución de {var} entre Pacientes con y sin Evento', fontsize=14)\n",
    "    plt.xlabel(var, fontsize=12)\n",
    "    plt.ylabel('Frecuencia', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967f267-e4bd-4141-a396-ed216ed11eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1cbeb9-80c5-4286-ba40-e3bb4a8b5c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7192474-fed6-4ee2-8045-cf2cc3ad42fd",
   "metadata": {},
   "source": [
    "### Análisis de Supervivencia "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf819c9-3828-4208-ad9b-b11790b36c93",
   "metadata": {},
   "source": [
    "#### Kaplan-Meier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e209b9-560e-4d3b-bffc-e8032f413106",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo1 = dfe[dfe['FEVI_pre'] <= 40]  # Grupo con FEVI_pre <= 40\n",
    "grupo2 = dfe[dfe['FEVI_pre'] > 40]  # Grupo con FEVI_pre > 40\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Grupo 1\n",
    "kmf.fit(durations=grupo1['tiempo_meses'], event_observed=grupo1['Muerte'])\n",
    "kmf.plot_survival_function(label='FEVI_pre <= 40', color='red')\n",
    "\n",
    "# Grupo 2\n",
    "kmf.fit(durations=grupo2['tiempo_meses'], event_observed=grupo2['Muerte'])\n",
    "kmf.plot_survival_function(label='FEVI_pre > 40', color='blue')\n",
    "\n",
    "plt.title('Curva de Supervivencia (Kaplan-Meier)')\n",
    "plt.xlabel('tiempo_meses')\n",
    "plt.ylabel('Probabilidad de Supervivencia')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "max_time = max(grupo1['tiempo_meses'].max(), grupo2['tiempo_meses'].max())  # Máximo valor de tiempo\n",
    "ticks = np.arange(0, max_time + 12, 12)  # Intervalos de 12 en 12 meses\n",
    "plt.xticks(ticks, labels=[str(int(tick)) for tick in ticks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e5870-da63-4e42-8c35-bb802229d4b8",
   "metadata": {},
   "source": [
    "#### log-rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0c15c-5b99-4e34-96ca-0d92f0c37c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# log-rank test\n",
    "result = logrank_test(\n",
    "    grupo1['tiempo_meses'], grupo2['tiempo_meses'],  # Tiempos de supervivencia de ambos grupos\n",
    "    event_observed_A=grupo1['Muerte'],             # Eventos (muerte) para el grupo 1\n",
    "    event_observed_B=grupo2['Muerte']              # Eventos (muerte) para el grupo 2\n",
    ")\n",
    "\n",
    "print(\"Estadístico de la prueba:\", result.test_statistic)\n",
    "print(\"p-valor:\", result.p_value)\n",
    "\n",
    "if result.p_value < 0.05:\n",
    "    print(\"Existen diferencias significativas entre las curvas de supervivencia.\")\n",
    "else:\n",
    "    print(\"No se encontraron diferencias significativas entre las curvas de supervivencia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878570f4-350e-4535-aa54-481c0d66cccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c153e17d-f276-43fc-a479-8e3ba0e31665",
   "metadata": {},
   "source": [
    "#### Regresión logística con variables escaladas y umbral optimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b89824-9a37-45e5-8bfb-813763aaf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Preparar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto', \n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte', 'Infarto', 'dias_muerte', \n",
    "           'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Escalar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# División train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Modelo\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predicción probabilística\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Índice de Youden para umbral óptimo\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "youden_index = tpr - fpr\n",
    "best_idx = np.argmax(youden_index)\n",
    "best_threshold = thresholds[best_idx]\n",
    "y_pred_adj = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Métricas\n",
    "cm = confusion_matrix(y_test, y_pred_adj)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensibilidad = tp / (tp + fn)\n",
    "especificidad = tn / (tn + fp)\n",
    "accuracy = accuracy_score(y_test, y_pred_adj)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Salidas\n",
    "print(f\"\\nMejor umbral según índice de Youden: {best_threshold:.2f}\")\n",
    "print(\"\\nMatriz de Confusión (con umbral óptimo):\")\n",
    "print(cm)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "print(f\"Sensibilidad (Recall): {sensibilidad:.2f}\")\n",
    "print(f\"Especificidad: {especificidad:.2f}\")\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_adj))\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Visualización: Matriz de Confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Evento', 'Evento'], yticklabels=['No Evento', 'Evento'])\n",
    "plt.title('Matriz de Confusión (Umbral Óptimo)')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicción')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC con punto óptimo\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='red')\n",
    "plt.scatter(fpr[best_idx], tpr[best_idx], color='black', label=f'Umbral óptimo (Youden = {best_threshold:.2f})', zorder=5)\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7255d-2fd9-4192-afdd-4b42545df17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2b78a-25b4-4b42-a131-ae9094c5cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convertir X_test a DataFrame con nombres originales de columnas\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "# Explicador SHAP para modelos lineales\n",
    "explainer = shap.Explainer(logreg, X_test_df)\n",
    "\n",
    "# Obtener valores SHAP\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "# Extraer valores SHAP en matriz (como en Random Forest)\n",
    "shap_array = shap_values.values  # array de tamaño (n_muestras, n_features)\n",
    "\n",
    "# Graficar SHAP Summary Plot con todas las variables\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_array, X_test_df, plot_type=\"dot\", max_display=len(X_test_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601de85-b44d-42df-a31e-dcac32d7888b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15a7df-b2e8-4fb8-b398-d7e755bc1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener nombres originales de las variables del DataFrame original\n",
    "feature_names = X.columns\n",
    "\n",
    "# Extraer coeficientes del modelo ya entrenado\n",
    "coefs = logreg.coef_[0]\n",
    "\n",
    "# Crear un DataFrame con nombres y coeficientes\n",
    "importancia_coef = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coeficiente': coefs,\n",
    "    'Importancia_absoluta': np.abs(coefs)\n",
    "})\n",
    "\n",
    "# Ordenar por importancia (valor absoluto del coeficiente)\n",
    "importancia_coef = importancia_coef.sort_values(by='Importancia_absoluta', ascending=False)\n",
    "\n",
    "# Mostrar tabla ordenada\n",
    "print(\"\\nCoeficientes del modelo de regresión logística ordenados por importancia:\")\n",
    "print(importancia_coef[['Variable', 'Coeficiente']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184e8dc-6140-44b6-abd2-5a740263ebd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "804731ed-87a6-4a73-9106-f2aa44da8269",
   "metadata": {},
   "source": [
    "#### Regresión Logística configurada con validacion cruzada y umbral optimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363affba-3331-4b3e-bbf8-6f5059b5b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, confusion_matrix, accuracy_score\n",
    ")\n",
    "\n",
    "# Preparar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto',\n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte',\n",
    "           'Infarto', 'dias_muerte', 'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc',\n",
    "           'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Estandarizar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "youden_thresholds = []\n",
    "youden_points = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "metricas_fold = []\n",
    "\n",
    "# Acumuladores para matriz de confusión total\n",
    "y_true_total = []\n",
    "y_pred_total = []\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_scaled, y), 1):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Índice de Youden\n",
    "    youden_index = tpr - fpr\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    youden_thresholds.append(best_threshold)\n",
    "    youden_points.append((fpr[best_idx], tpr[best_idx]))\n",
    "\n",
    "    # Predicción binaria con umbral óptimo\n",
    "    y_pred = (y_prob >= best_threshold).astype(int)\n",
    "\n",
    "    # Guardar predicciones\n",
    "    y_true_total.extend(y_test)\n",
    "    y_pred_total.extend(y_pred)\n",
    "\n",
    "    # Métricas\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensibilidad = tp / (tp + fn)\n",
    "    especificidad = tn / (tn + fp)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    metricas_fold.append({\n",
    "        'Fold': fold_idx,\n",
    "        'AUC': roc_auc,\n",
    "        'Sensibilidad': sensibilidad,\n",
    "        'Especificidad': especificidad,\n",
    "        'Accuracy': accuracy,\n",
    "        'Umbral óptimo (Youden)': best_threshold\n",
    "    })\n",
    "\n",
    "    # Curva ROC\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1.5, alpha=0.6,\n",
    "             label=f'Fold {fold_idx} (AUC = {roc_auc:.2f}, Youden = {best_threshold:.2f})')\n",
    "\n",
    "# Media de curvas ROC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "mean_threshold = np.mean(youden_thresholds)\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='black',\n",
    "         label=f'Media (AUC = {mean_auc:.2f}, Youden = {mean_threshold:.2f})',\n",
    "         lw=2.5, linestyle='--')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1)\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curvas ROC por Fold y Media\\nRegresión Logística con Validación Cruzada (Youden)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabla de métricas\n",
    "df_metricas = pd.DataFrame(metricas_fold)\n",
    "print(\"\\nMétricas por Fold:\")\n",
    "print(df_metricas)\n",
    "\n",
    "# Promedio de métricas\n",
    "print(\"\\nPromedio de métricas:\")\n",
    "print(df_metricas.drop(columns='Fold').mean())\n",
    "\n",
    "# Matriz de Confusión Total\n",
    "cm_total = confusion_matrix(y_true_total, y_pred_total)\n",
    "print(\"\\nMatriz de Confusión Total:\")\n",
    "print(cm_total)\n",
    "\n",
    "# Mostrar matriz de confusión total como heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_total, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Evento', 'Evento'], yticklabels=['No Evento', 'Evento'])\n",
    "plt.title('Matriz de Confusión Total\\nValidación Cruzada (Umbral Youden por Fold)')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicción')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c3ab2-3030-443f-a751-edce67d8d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preparar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto',\n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte',\n",
    "           'Infarto', 'dias_muerte', 'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc',\n",
    "           'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Estandarizar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Entrenar modelo sobre todos los datos\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "logreg.fit(X_df_scaled, y)\n",
    "\n",
    "# Crear un masker para datos independientes (nuevo enfoque recomendado)\n",
    "masker = shap.maskers.Independent(data=X_df_scaled)\n",
    "\n",
    "# Crear el explicador SHAP sin el parámetro obsoleto\n",
    "explainer = shap.Explainer(logreg, masker)\n",
    "\n",
    "# Obtener valores SHAP\n",
    "shap_values = explainer(X_df_scaled)\n",
    "\n",
    "# Graficar todos los valores SHAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values.values, X_df_scaled, plot_type=\"dot\", max_display=len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a22f0b-3e31-4689-8f6b-96e7811338b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bdd1e-7c92-4c5c-a208-ae473ba1de8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ff0b5-c0f1-4765-86e8-a7c149a70ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ffe0b-0c01-4915-9c51-1fbbcd2ad7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94557d69-6321-4935-a544-f2e6ab7531e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionar las columnas de X después de la exclusión\n",
    "print(\"Columnas seleccionadas:\", X.columns.tolist())\n",
    "\n",
    "# Verificar tipos de datos\n",
    "print(\"Tipos de datos en X:\")\n",
    "print(X.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164597b3-dbeb-4d10-96fe-9639278d2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar valores únicos en cada columna\n",
    "for col in X.columns:\n",
    "    print(f\"Columna: {col}, Tipos: {X[col].map(type).unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2f80e-2406-4173-b875-7f68aba191ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcc00b-e6e5-4090-9893-c81f1efe2242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4c5a7-8017-4d69-a1c8-4470946a865a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d06a83a1-5bbd-40f9-9b72-a85cbe22131d",
   "metadata": {},
   "source": [
    "#### Validacion cruzada datos escalados + Youden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225c730-d958-4f8c-a83e-45ea2112f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_auc_score, accuracy_score, recall_score, precision_score, f1_score, roc_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar y preparar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto', \n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte', 'Infarto', 'dias_muerte',\n",
    "           'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Configurar validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "overall_confusion_matrix = np.zeros((2, 2))\n",
    "\n",
    "# Ejecutar validación cruzada\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_scaled, y), 1):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Modelo\n",
    "    logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Predicciones probabilísticas\n",
    "    y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcular índice de Youden para encontrar el mejor umbral\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    youden_index = tpr - fpr\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    # Clasificación con umbral óptimo\n",
    "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    # Métricas\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    overall_confusion_matrix += cm\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Fold {fold}: Mejor umbral (Youden) = {best_threshold:.2f}\")\n",
    "    print(f\"Fold {fold}: Sensibilidad = {recall:.2f}, Especificidad = {cm[0,0]/(cm[0,0]+cm[0,1]):.2f}, Accuracy = {accuracy:.2f}\\n\")\n",
    "\n",
    "    fold_results.append({\n",
    "        'Fold': fold,\n",
    "        'Threshold': best_threshold,\n",
    "        'Accuracy': accuracy,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "\n",
    "# Resultados\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(\"Resultados por Fold:\")\n",
    "print(results_df)\n",
    "\n",
    "# Promedios\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "print(\"\\nPromedio de métricas:\")\n",
    "print(mean_results)\n",
    "\n",
    "# Matriz de confusión total\n",
    "print(\"\\nMatriz de Confusión Total:\")\n",
    "print(overall_confusion_matrix)\n",
    "\n",
    "# Visualización de métricas por fold\n",
    "results_df[['Accuracy', 'Recall', 'Precision', 'F1 Score', 'ROC-AUC']].boxplot()\n",
    "plt.title('Distribución de métricas por Fold (Umbral óptimo Youden)')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce97c829-3004-4192-a10f-2f2f3afa7bf4",
   "metadata": {},
   "source": [
    "#### Curvas ROC folds validacion cruzada + youden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ad5935-2a8a-483d-a461-d2c64903c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import to_rgba\n",
    "from matplotlib import colormaps\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto', \n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte', 'Infarto', 'dias_muerte',\n",
    "           'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Función para aclarar colores\n",
    "def lighten_color(color, amount=0.5):\n",
    "    r, g, b, a = to_rgba(color)\n",
    "    return (r + (1 - r) * amount, g + (1 - g) * amount, b + (1 - b) * amount, a)\n",
    "\n",
    "# Preparar colores\n",
    "colors = colormaps['tab10']\n",
    "colors_light = [lighten_color(colors(i / 9), amount=0.5) for i in range(5)]\n",
    "\n",
    "# Variables para curva promedio\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Graficar curvas ROC por fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_scaled, y), 1):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Entrenar modelo\n",
    "    logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Curva ROC y Youden\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    youden_index = tpr - fpr\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_fpr = fpr[best_idx]\n",
    "    best_tpr = tpr[best_idx]\n",
    "\n",
    "    # Interpolación para curva media\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Dibujar curva ROC del fold\n",
    "    plt.plot(fpr, tpr, color=colors_light[fold - 1],\n",
    "             label=f'Fold {fold} (AUC = {roc_auc:.2f}, Threshold = {best_threshold:.2f})')\n",
    "    \n",
    "    # Punto óptimo\n",
    "    plt.scatter(best_fpr, best_tpr, color=colors_light[fold - 1], edgecolors='black', zorder=5)\n",
    "\n",
    "# Curva ROC media\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue', linewidth=2, label=f'Mean ROC (AUC = {mean_auc:.2f})')\n",
    "\n",
    "# Línea de referencia\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='red')\n",
    "\n",
    "# Estética\n",
    "plt.title('Curvas ROC por Fold con Umbral Óptimo (Youden)', fontsize=16)\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e04206-7a49-4b31-a425-851b67ec5077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bdf577-92e3-4d17-8a08-affc54b793cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaba14-9f3f-4484-9623-55bcf152df65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7657789a-479f-48e1-9f67-a6e4767ab6d2",
   "metadata": {},
   "source": [
    "#### Extraemos variabes de mayor peso de la validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25c4e0-7dc2-46f7-a5cf-681e334ed7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Obtener coeficientes absolutos del modelo ya entrenado\n",
    "feature_importance = pd.Series(np.abs(logreg.coef_[0]), index=X.columns)\n",
    "\n",
    "# Ordenar de mayor a menor importancia\n",
    "top3_vars_cv = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "# Excluir 'tiempo_meses' si estuviera\n",
    "top3_vars_cv = [var for var in top3_vars_cv.index if var != 'tiempo_meses'][:3]\n",
    "\n",
    "print(\"Top 3 variables según regresión logística (validación cruzada):\", top3_vars_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bfcb9-d702-421f-8dd3-ea2c72338c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd190a1-3732-4d71-a2e7-9ed59543fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos las columnas que no están en la lista \"excluir\"\n",
    "df_filtrado = dfe.drop(columns=excluir)\n",
    "df_filtrado.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede45ba-822d-4345-bf80-2415114611c3",
   "metadata": {},
   "source": [
    "#### Riesgos proporcionales de Cox (tres variables de mayor peso en Validación Cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d18c4-4c87-4d9c-8af6-89f65225505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# df para modelo de Cox con esas variables\n",
    "df_cox = dfe[['tiempo_meses', 'Muerte_o_Infarto'] + top3_vars_cv].dropna()\n",
    "\n",
    "# Paso 2: Modelo de Cox con esas variables\n",
    "modelo_cox = smf.phreg(\n",
    "    formula=\"tiempo_meses ~ \" + \" + \".join(top3_vars_cv),\n",
    "    data=df_cox,\n",
    "    status=df_cox[\"Muerte_o_Infarto\"],\n",
    "    ties=\"efron\"\n",
    ")\n",
    "\n",
    "# Ajustamos modelo\n",
    "resultado = modelo_cox.fit()\n",
    "print(resultado.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1574da-d747-4b7e-859b-416e570edc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfcb5d-dd5a-4660-9eca-2f55a2e65999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable tipo_procedimiento (ACTP = 0, Pontaje Aortocoronario = 1)\n",
    "print(dfe['tipo_procedimiento'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35da63b-4fa0-4129-85c0-e5b1a3434ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b670cf0f-d35d-4043-b2c0-e3a17f2c16a4",
   "metadata": {},
   "source": [
    "#### Validacion cruzada datos escalados + Youden (configurada con Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35902ba4-9536-4361-b624-9d2137543ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_auc_score, accuracy_score, recall_score, precision_score, f1_score, roc_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar y preparar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto', \n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte', 'Infarto', 'dias_muerte',\n",
    "           'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Configurar validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "overall_confusion_matrix = np.zeros((2, 2))\n",
    "\n",
    "# Ejecutar validación cruzada\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_scaled, y), 1):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Modelo: Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predicciones probabilísticas\n",
    "    y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcular índice de Youden para encontrar el mejor umbral\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    youden_index = tpr - fpr\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    # Clasificación con umbral óptimo\n",
    "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    # Métricas\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    overall_confusion_matrix += cm\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Fold {fold}: Mejor umbral (Youden) = {best_threshold:.2f}\")\n",
    "    print(f\"Fold {fold}: Sensibilidad = {recall:.2f}, Especificidad = {cm[0,0]/(cm[0,0]+cm[0,1]):.2f}, Accuracy = {accuracy:.2f}\\n\")\n",
    "\n",
    "    fold_results.append({\n",
    "        'Fold': fold,\n",
    "        'Threshold': best_threshold,\n",
    "        'Accuracy': accuracy,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "\n",
    "# Resultados\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(\"Resultados por Fold:\")\n",
    "print(results_df)\n",
    "\n",
    "# Promedios\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "print(\"\\nPromedio de métricas:\")\n",
    "print(mean_results)\n",
    "\n",
    "# Matriz de confusión total\n",
    "print(\"\\nMatriz de Confusión Total:\")\n",
    "print(overall_confusion_matrix)\n",
    "\n",
    "# Visualización de métricas por fold\n",
    "results_df[['Accuracy', 'Recall', 'Precision', 'F1 Score', 'ROC-AUC']].boxplot()\n",
    "plt.title('Distribución de métricas por Fold (Random Forest + Youden)')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d2de2-bb8d-45b2-837a-01ae0247fcd1",
   "metadata": {},
   "source": [
    "#### Curvas ROC folds validacion cruzada + youden (configurada con Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a664647-9d56-470c-8da1-9b94c388f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import to_rgba\n",
    "from matplotlib import colormaps\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto', \n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte', 'Infarto', 'dias_muerte',\n",
    "           'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Función para aclarar colores\n",
    "def lighten_color(color, amount=0.5):\n",
    "    r, g, b, a = to_rgba(color)\n",
    "    return (r + (1 - r) * amount, g + (1 - g) * amount, b + (1 - b) * amount, a)\n",
    "\n",
    "# Preparar colores\n",
    "colors = colormaps['tab10']\n",
    "colors_light = [lighten_color(colors(i / 9), amount=0.5) for i in range(5)]\n",
    "\n",
    "# Variables para curva promedio\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Graficar curvas ROC por fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_scaled, y), 1):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Entrenar modelo\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Curva ROC y Youden\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    youden_index = tpr - fpr\n",
    "    best_idx = np.argmax(youden_index)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_fpr = fpr[best_idx]\n",
    "    best_tpr = tpr[best_idx]\n",
    "\n",
    "    # Interpolación para curva media\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Dibujar curva ROC del fold\n",
    "    plt.plot(fpr, tpr, color=colors_light[fold - 1],\n",
    "             label=f'Fold {fold} (AUC = {roc_auc:.2f}, Threshold = {best_threshold:.2f})')\n",
    "    \n",
    "    # Punto óptimo\n",
    "    plt.scatter(best_fpr, best_tpr, color=colors_light[fold - 1], edgecolors='black', zorder=5)\n",
    "\n",
    "# Curva ROC media\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue', linewidth=2, label=f'Mean ROC (AUC = {mean_auc:.2f})')\n",
    "\n",
    "# Línea de referencia\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='red')\n",
    "\n",
    "# Estética\n",
    "plt.title('Curvas ROC por Fold con Umbral Óptimo (Youden) - Random Forest', fontsize=16)\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df40abb-ad42-467e-b8ae-73f1760ea7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38da29f8-95ee-45d4-922a-287596d2f0ef",
   "metadata": {},
   "source": [
    "#### Extraemos variabes de mayor peso de la validacion cruzada + youden (configurada con Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873eeb02-1e0b-4720-8e90-d8176743f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar y preparar datos\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto', \n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte', 'Infarto', 'dias_muerte',\n",
    "           'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "X = dfe.drop(columns=excluir, errors='ignore')\n",
    "y = dfe['Muerte_o_Infarto']\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Configurar validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Acumulador de importancias\n",
    "importancias_acumuladas = np.zeros(X.shape[1])\n",
    "\n",
    "# Entrenar modelos y acumular importancias\n",
    "for train_idx, test_idx in cv.split(X_scaled, y):\n",
    "    X_train, y_train = X_scaled[train_idx], y.iloc[train_idx]\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    importancias_acumuladas += rf.feature_importances_\n",
    "\n",
    "# Calcular importancia media\n",
    "importancia_media = importancias_acumuladas / cv.get_n_splits()\n",
    "\n",
    "# Crear Series con nombres de variables\n",
    "feature_importance_rf = pd.Series(importancia_media, index=X.columns)\n",
    "\n",
    "# Ordenar y seleccionar las 3 más importantes\n",
    "top3_vars_cv_rf = feature_importance_rf.sort_values(ascending=False)\n",
    "\n",
    "# Excluir 'tiempo_meses' si estuviera\n",
    "top3_vars_cv_rf = [var for var in top3_vars_cv_rf.index if var != 'tiempo_meses'][:3]\n",
    "\n",
    "print(\"Top 3 variables según Random Forest (validación cruzada):\", top3_vars_cv_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6586c1-ee92-4294-8137-e02de7fb223c",
   "metadata": {},
   "source": [
    "#### Riesgos proporcionales de Cox (tres variables de mayor peso en Validación Cruzada + Youden) (configurada con Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11df66d-8173-4cc2-8e83-f37f4a75ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# df para modelo de Cox con esas variables\n",
    "df_cox_rf = dfe[['tiempo_meses', 'Muerte_o_Infarto'] + top3_vars_cv_rf].dropna()\n",
    "\n",
    "# Paso 2: Modelo de Cox con esas variables\n",
    "modelo_cox_rf = smf.phreg(\n",
    "    formula=\"tiempo_meses ~ \" + \" + \".join(top3_vars_cv_rf),\n",
    "    data=df_cox_rf,\n",
    "    status=df_cox_rf[\"Muerte_o_Infarto\"],\n",
    "    ties=\"efron\"\n",
    ")\n",
    "\n",
    "# Ajustamos modelo\n",
    "resultado_rf = modelo_cox_rf.fit()\n",
    "print(resultado_rf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ef76b-c0d5-4164-89cf-43d436f99db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db31e0-3b34-41ea-b42b-91b81bef5d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94688c-4f3a-4511-92d7-7188d92f0379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812fe3b-9110-4582-addb-a6a7f370cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8212e-cd67-4c72-9643-ad84d0bb3597",
   "metadata": {},
   "source": [
    "#### Random Forest (Umbral optimo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b8714-74d0-45ca-a884-eb2b8eb10e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "excluir = ['Muerte_o_Infarto', 'NHC', 'ApellidosyNombre', 'Fecha_Intervención', 'fecha_alta', 'Fecha_muerte', 'Fecha_infarto', \n",
    "           'Fecha_Nueva_revascularización', 'Fecha_Ingreso_ICC', 'Causa', 'tipo_causa', 'Tipo_intervención_mitral', 'Muerte', 'Infarto', 'dias_muerte', \n",
    "           'Nueva_revascularización', 'Ingeso_ICC', 'DA_revasc', 'Cx_revasc', 'CD_revasc', 'Tabaquismo_Rec', 'dias_FEVI_post', 'tiempo_meses', 'FEVI_post', 'dias_FEVI_pre']\n",
    "\n",
    "X = dfe.drop(columns=excluir, errors='ignore')  # Variables independientes\n",
    "y = dfe['Muerte_o_Infarto']  # Variable dependiente\n",
    "\n",
    "# Escalamos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividimos datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenamos modelo Random Forest \n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Probabilidades predichas\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]  # Probabilidades de la clase positiva\n",
    "\n",
    "# Calculamos curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Determinamos umbral óptimo máximo de sens + esp\n",
    "youden_index = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_index)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Umbral óptimo (máximo sensibilidad + especificidad): {optimal_threshold:.2f}\")\n",
    "\n",
    "# Predicciones con umbral óptimo\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Matriz de confusión con umbral óptimo\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "print(\"Matriz de Confusión (Umbral Óptimo):\")\n",
    "print(cm)\n",
    "\n",
    "# sensibilidad, especificidad y precisión\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensibilidad = tp / (tp + fn)\n",
    "especificidad = tn / (tn + fp)\n",
    "exactitud = accuracy_score(y_test, y_pred_optimal)\n",
    "\n",
    "print(f\"\\nExactitud: {exactitud:.2f}\")\n",
    "print(f\"Sensibilidad (Recall): {sensibilidad:.2f}\")\n",
    "print(f\"Especificidad: {especificidad:.2f}\")\n",
    "\n",
    "print(\"\\nReporte de Clasificación (Umbral Óptimo):\")\n",
    "print(classification_report(y_test, y_pred_optimal, zero_division=0))\n",
    "\n",
    "# Métricas adicionales\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "precision = precision_score(y_test, y_pred_optimal, average='macro', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred_optimal, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_optimal, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.2f}\")\n",
    "print(f\"Precisión (macro): {precision:.2f}\")\n",
    "print(f\"Recall (macro): {recall:.2f}\")\n",
    "print(f\"F1-Score (macro): {f1:.2f}\")\n",
    "\n",
    "# Visualización de resultados\n",
    "# Matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Evento', 'Evento'], yticklabels=['No Evento', 'Evento'])\n",
    "plt.title('Matriz de Confusión (Umbral Óptimo)')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicción')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})', color='blue')\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', label=f'Optimal Threshold ({optimal_threshold:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='red')  # Línea de referencia\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Validación cruzada para evaluar el modelo\n",
    "cv_scores = cross_val_score(rf, X_scaled, y, cv=5, scoring='accuracy')  # 5 particiones\n",
    "print(\"Resultados de Validación Cruzada (Accuracy):\", cv_scores)\n",
    "print(f\"Promedio de Validación Cruzada: {cv_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03f574-36f5-4f71-a6f5-58e5055c7c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb44c33-6b66-41fe-8f55-3e8071336dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c053286-3ddd-4199-b6cc-b4b8ff2a39e7",
   "metadata": {},
   "source": [
    "##### Importancia de variables por reducción de impureza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86f75d-27b4-4cb8-a446-9e7eb4bf2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de variables por reducción de impureza\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Recuperar nombres de variables originales\n",
    "feature_names = X.columns\n",
    "\n",
    "# Obtener importancias y ordenarlas\n",
    "importancias = rf.feature_importances_\n",
    "importancias_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Importancia': importancias\n",
    "}).sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "# Mostrar TODAS las variables en el gráfico\n",
    "plt.figure(figsize=(10, len(importancias_df) * 0.3))  # Ajusta alto en función del número de variables\n",
    "sns.barplot(x='Importancia', y='Variable', data=importancias_df, palette='viridis')\n",
    "plt.title('Importancia de variables según reducción de impureza')\n",
    "plt.xlabel('Importancia normalizada')\n",
    "plt.ylabel('Variable')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (Opcional) Mostrar la tabla completa en pantalla\n",
    "print(\"\\nImportancia de todas las variables (ordenadas):\")\n",
    "print(importancias_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e41b76-18a1-4ee8-8061-677881c56443",
   "metadata": {},
   "source": [
    "##### Importancia de variables por reducción de impureza (Top 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db2724-0bf3-4ff1-9152-7befb2677111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de variables por reducción de impureza\n",
    "import pandas as pd\n",
    "\n",
    "# Recuperar nombres de variables originales\n",
    "feature_names = X.columns\n",
    "\n",
    "# Obtener importancias y ordenarlas\n",
    "importancias = rf.feature_importances_\n",
    "importancias_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Importancia': importancias\n",
    "}).sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "# Mostrar top 15 más importantes (puedes ajustar a tus necesidades)\n",
    "top_n = 15\n",
    "top_importancias = importancias_df.head(top_n)\n",
    "\n",
    "# Gráfico de barras horizontal\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importancia', y='Variable', data=top_importancias, palette='viridis')\n",
    "plt.title(f'Importancia de variables según reducción de impureza (top {top_n})')\n",
    "plt.xlabel('Importancia normalizada')\n",
    "plt.ylabel('Variable')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (Opcional) Mostrar la tabla completa en pantalla\n",
    "print(\"\\nImportancia de todas las variables (ordenadas):\")\n",
    "print(importancias_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebe6df-aca0-414d-99c9-8688b55b85e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99ed964a-2536-4d4b-ac25-134c98df4674",
   "metadata": {},
   "source": [
    "#### Gráfico Shap Values (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe755b-e8d2-41ec-b665-8691b22fde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir X_test de nuevo a DataFrame con nombres de columnas\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "# Explicador SHAP basado en árboles\n",
    "explainer = shap.TreeExplainer(rf, feature_perturbation=\"tree_path_dependent\")\n",
    "\n",
    "# Obtener valores SHAP\n",
    "shap_values = explainer.shap_values(X_test_df)\n",
    "\n",
    "# Si hay más de una clase, seleccionamos la clase positiva\n",
    "if isinstance(shap_values, list):  \n",
    "    shap_values = shap_values[1]  # Para clasificación binaria con lista\n",
    "elif shap_values.ndim == 3:\n",
    "    shap_values = shap_values[:, :, 1]  # Para clasificación binaria con array 3D\n",
    "\n",
    "# Graficar SHAP Summary Plot con todas las variables\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test_df, plot_type=\"dot\", max_display=len(X_test_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b7b40-0825-4943-9d24-079b8fb3e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calcular importancia media absoluta de los SHAP values\n",
    "shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Obtener índice ordenado (descendente) de importancia\n",
    "sorted_idx = np.argsort(shap_importance)[::-1]\n",
    "\n",
    "# Obtener las 4 variables más importantes\n",
    "top4_vars = X_test_df.columns[sorted_idx[:4]].tolist()\n",
    "\n",
    "# Eliminar 'tiempo_meses' si está presente\n",
    "top3_vars_shap = [var for var in top4_vars if var != 'tiempo_meses'][:3]\n",
    "\n",
    "print(\"Top 3 variables según SHAP values (excluyendo tiempo_meses):\")\n",
    "print(top3_vars_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11458caf-f178-4a87-80b7-69a17c651134",
   "metadata": {},
   "outputs": [],
   "source": [
    "'DA_sin_revasc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cfb55-1e4e-49c7-9414-98ef4cf0dd93",
   "metadata": {},
   "source": [
    "#### Riesgos proporcionales de Cox (tres variables de mayor peso en Shap values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a616921-bd23-48ff-9981-a90db9d51ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Asegúrate de que no haya valores nulos en las variables seleccionadas\n",
    "variables_shap = ['FEVI_pre', 'edad_ingreso', 'HTA']\n",
    "variables_modelo = ['tiempo_meses', 'Muerte_o_Infarto'] + variables_shap\n",
    "\n",
    "# Filtrar y eliminar filas con datos faltantes\n",
    "df_cox_shap = dfe[variables_modelo].dropna()\n",
    "\n",
    "# Definir la fórmula del modelo de Cox\n",
    "formula_cox = \"tiempo_meses ~ \" + \" + \".join(variables_shap)\n",
    "\n",
    "# Ajustar el modelo de riesgos proporcionales de Cox\n",
    "modelo_cox_shap = smf.phreg(\n",
    "    formula=formula_cox,\n",
    "    data=df_cox_shap,\n",
    "    status=df_cox_shap[\"Muerte_o_Infarto\"],  # Variable de evento (1=evento, 0=censura)\n",
    "    ties=\"efron\"  # Método para manejo de empates (recomendado)\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "resultado_shap = modelo_cox_shap.fit()\n",
    "\n",
    "# Mostrar resumen de resultados\n",
    "print(resultado_shap.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
